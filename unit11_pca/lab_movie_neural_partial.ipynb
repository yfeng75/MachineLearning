{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab:  Low-Rank Approximation for Movie Recommendations\n",
    "\n",
    "A common application of low-rank approximation is for recommender systems.  In this lab, we will create a very primitive recommendation system for movies.  Through the lab, you will learn to:\n",
    "\n",
    "* Represent ratings data as a sparse matrix\n",
    "* Evaluate the mean absolute error (MAE) using simple movie or user biases\n",
    "* Create a low-rank model in Tensorflow for predicting the movie rating using `Embedding` layers\n",
    "* Train the model and optimize the embedding dimension.\n",
    "* Make predictions on new users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the MovieLens Dataset\n",
    "\n",
    "We first load some common packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[GroupLens](https://grouplens.org/) is a research organization at the University of Minnesota that has done extensive work in recommendation systems among other topics.  They have excellent datasets on movie recommendations as part of their [MovieLens project](https://movielens.org/).  In this lab, we will use a relatively small dataset, `Movielens 1m` that has 1 million ratings.  If you are interested in continuing research in this area, they have much larger datasets as well.  But, this relatively small one is sufficient to illustrate the basic concepts.\n",
    "\n",
    "To get the data, go to the webpage:\n",
    "\n",
    "https://grouplens.org/datasets/movielens/latest/\n",
    "\n",
    "and download and unzip the files, `ml-1m.zip`.  Alternatively, you can just run the following command which will download unzip the file for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ml-1m.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-f2d8d1dba5e0>:27: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  with tqdm.tqdm_notebook(total=total_size//block_size, unit='kB',\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cdf88c85e31403b8d6833dfed7deb5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5778.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unzipping ml-1m.zip...\n",
      "Unzip completed\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import requests\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Set the files names for movies and ratings files\n",
    "ml_dir = 'ml-1m'\n",
    "ratings_fn = os.path.join(ml_dir,'ratings.dat')\n",
    "movies_fn = os.path.join(ml_dir,'movies.dat')\n",
    "\n",
    "def download_file(src_url, dst_fn):\n",
    "    \n",
    "    if os.path.exists(dst_fn):\n",
    "        print('File %s already exists' % dst_fn)\n",
    "        return\n",
    "    \n",
    "    print('Downloading %s' % dst_fn)\n",
    "    \n",
    "    # Streaming, so we can iterate over the response.\n",
    "    r = requests.get(src_url, stream=True)\n",
    "\n",
    "    # Total size in MB.\n",
    "    total_size = int(r.headers.get('content-length', 0)); \n",
    "    block_size = 1024\n",
    "    wrote = 0 \n",
    "    with open(dst_fn, 'wb') as f:\n",
    "        with tqdm.tqdm_notebook(total=total_size//block_size, unit='kB', \n",
    "                           unit_scale=True, unit_divisor=1024) as pbar:\n",
    "            for data in r.iter_content(block_size):\n",
    "                wrote = wrote + len(data)\n",
    "                pbar.update(1)\n",
    "                f.write(data)\n",
    "    if total_size != 0 and wrote != total_size:\n",
    "        print(\"ERROR, something went wrong\") \n",
    "\n",
    "# Test if all files are downloaded\n",
    "files_exists = False\n",
    "if os.path.exists(ml_dir):\n",
    "    if os.path.exists(ratings_fn) and os.path.exists(movies_fn):\n",
    "        files_exists = True\n",
    "\n",
    "if files_exists:\n",
    "    print('Files %s and %s already downloaded' % (ratings_fn, movies_fn))\n",
    "\n",
    "else:\n",
    "    # First download the zip file if needed\n",
    "    src_url = 'http://files.grouplens.org/datasets/movielens/ml-1m.zip'\n",
    "    dst_fn = 'ml-1m.zip'\n",
    "    download_file(src_url, dst_fn)\n",
    "    \n",
    "    # Then, unzip the file\n",
    "    print('Unzipping %s...' % dst_fn)\n",
    "    zip_ref = zipfile.ZipFile(dst_fn, 'r')\n",
    "    zip_ref.extractall('.')\n",
    "    zip_ref.close()\n",
    "    print('Unzip completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the movies files with the `read_csv` command.  Print the first 5 entries of the dataframe.  You will see that the file has a list of movies.  Each movie has a `movieId` and `title`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:  Read the movies \n",
    "import os\n",
    "\n",
    "# TODO:  Use the movies.head() to display the first 5 entries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the following columns from the `movies` dataframe:\n",
    "*  Extract the `movieId` column, convert to an `np.array` and store in `movie_ids`\n",
    "*  Extract the `title` column, convert to a list (using `.tolist()`) and store in `titles`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# movie_id = ...\n",
    "# titles = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function returns the string of a movie title, given its movie id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_title(movie_id):\n",
    "    I = np.where(movie_ids == movie_id)[0]\n",
    "    if len(I) == 0:\n",
    "        return 'unknown'\n",
    "    else:\n",
    "        return titles[I[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the `ratings.dat` file into a `pandas` dataframe `ratings`.  Use the `head` method to print the first five rows of the dataframe.  This is a large file, so it may take a minute to read in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# ratings = ...\n",
    "#ratings = pd.read_csv(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract three columns from the `ratings` dataframe:\n",
    "\n",
    "* Set `user` to `ratings['userId']`,\n",
    "* Set `movie` to `ratings['movieId']`\n",
    "* Set `y` to `ratings['rating']`\n",
    "\n",
    "Convert to each to an `np.array`.  Print:\n",
    "\n",
    "* Total number of movies (the maximum movie index)\n",
    "* Total number of users\n",
    "* Total number of ratings\n",
    "* The average fraction of movies rated per user\n",
    "\n",
    "You should see that only a small fraction of the movies are rated by each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "#   user = ...\n",
    "#   movie = ...\n",
    "#   y = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal will be to predict the rating `y` from the indices `movie` and `user`.  We need to split the data into training and test.\n",
    "Create training and test data of the form:\n",
    "\n",
    "* Training data:  `Xtr = [usertr, movietr]` and `ytr` for approximately 75% of the samples.\n",
    "* Test data:  `Xts = [userts, moviets]` and `yts` for approximately 25% of the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "#   Xtr, ytr = ...\n",
    "#   Xts, yts = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Rating Prediction Based on Average Rating\n",
    "\n",
    "Before we try to perform a complex algorithm for predicting a movie rating, we will first compute some simple statistics to get you familar with the data set.  First, compute the average movie rating across all movies in the training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, find the average rating per movie id. For each movie id, `i` compute `ymean[i]`, the average rating for that movie in the training data set and `ycnt[i]`, the number of ratings the movie had.  If `ycnt[i]==0`, set `ymean[i]=y0`, where `y0` is the average overall rating. \n",
    "\n",
    "You will want to think about how you do this computation efficiently since the data set `ytr` has a large number of entries.  Make you sure you go over the entries in `ytr` only once.  Even if you do it efficiently, it will take a minute, so you may want to add a progress bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# ymean = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print all the movies that had an average rating over 4.8.  Print their titles, the average rating and the number of ratings they had.  You will see that most of the movies with very high ratings had very few ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for each `i` in the test data set, compute `yhat[i]` to be the mean rating for the movie in rating `i`.  Find the average value `|yhat[i]-yts[i]|`.  This is called the *mean absolute error* or MAE and is a common metric in evaluating recommendation predictions.  If you did everything correctly, you should get an MAE ~= 0.78.  That means that simply using the average movie rating by users will predict the rating of another user within 0.78 on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "#   yhat = ...\n",
    "#   mae = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Neural Network Recommender\n",
    "We now build a neural network for predicting the ratings.  First, we load the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Input, Embedding, Dot, Reshape, Dense, Flatten, Add, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a neural network in Tensorflow as follows:\n",
    "\n",
    "*  Set the embedding dimension to `emb_dim=4`.  \n",
    "*  Let `userid_in` and `movieid_in` be the input user and movie indices.  These can be created in Tensorflow with `Input` layers with `shape = (1,)`. \n",
    "*  The user index generates a bias `user_bias`.  Use an `Embedding` layer with `output_dim=1` followed by a `Flatten` layer.  \n",
    "*  The user index also generates a weight `user_wt`.  Use a second `Embedding` layer with `output_dim=emb_dim` followed by a `Flatten` layer.  \n",
    "*  The movie index generates biases `movie_bias` and `movie_wt` similar to the user bias.\n",
    "*  We then make the rating prediction with `yhat = Dot(user_wt, movie_wt) + user_bias + movie_bias`. \n",
    "*  Optionally, you can add bias and weight regularization, although I found these did not help significantly.\n",
    "*  Set the model to `mod = Model([userid_in, movieid_in], yhat)`.\n",
    "\n",
    "Print a summary of the model `mod.summary()`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "#    K.clear_session()\n",
    "#    mod = ...\n",
    "#    mod.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model with `Adam` optimizer with a learning rate of `0.01` (I found these numbers to work out well).  Use the \n",
    "`'mean_absolute_error'` loss.  Then fit the model with 8 epochs.  Use a batch size of 1000.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "#    opt = ...\n",
    "#    mod.compile(...)\n",
    "#    mod.fit(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the training and test loss as a function of the epochs.  If you did it correctly the final test loss should be around  0.71 and the training loss should be 0.68.  This is a little better than the MAE you get just using the average movie rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions!\n",
    "\n",
    "Select a random user, `user_id`.  Then, for each movie index, use the model to predict the ratings. Set the predictions to `yhat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "#    user_id = ...\n",
    "#    yhat = mod.predict(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the names of the movies with the top 10 predicted ratings for the user as well as the average rating that those movies had.  You will see that the network may predict ratings above 5!  We could have avoided this by limiting the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus:  Optimizing the Embedding Dimension\n",
    "\n",
    "You can try to optimize the embedding dimension.  Try different dimensions from 0 to 8.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training and test loss as a function of the embedding layer. We see we get a minimum with an embedding dimension around 4 or 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
